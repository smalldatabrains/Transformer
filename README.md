# Transformer discovery

This is just an attempt to train a transformer model based on the 2017 paper from Google 'Attention is all you need' using pytorch framework
https://arxiv.org/pdf/1706.03762

please reefer to pytorch documentation for a proper local installation
https://pytorch.org/get-started/locally/

3 classes are defined:
- Positional encoding
- The neural network model itself : complex layers (Transformer Encoder and decoder) are already built in pytorch framework
- A sample dataset class for testing

